{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "from torch import nn\n",
    "\n",
    "import tianshou as ts\n",
    "from tianshou.utils import TensorboardLogger, WandbLogger\n",
    "from torch.utils.tensorboard import SummaryWriter, writer\n",
    "\n",
    "from agents import TwoAgentPolicy\n",
    "from agents.lib_agents import SinePolicy\n",
    "from agents.lib_agents import SAC\n",
    "\n",
    "from utils import make_render_env, make_env, make_discrete_env, make_render_discrete_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devanshu/.local/lib/python3.9/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "# create environment\n",
    "\n",
    "env = make_env()\n",
    "train_envs = ts.env.DummyVectorEnv([make_env for _ in range(10)])\n",
    "test_envs = ts.env.DummyVectorEnv([make_render_env for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating policies\n",
    "\n",
    "p1 = SinePolicy()\n",
    "p2 = SAC(env.action_space['bar'], env.observation_space.shape, env.action_space['bar'].shape)(n_step=1)\n",
    "policy = TwoAgentPolicy(observation_space=env.observation_space, action_space=env.action_space, policies=(p1, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup collector\n",
    "\n",
    "train_collector = ts.data.Collector(policy, train_envs, ts.data.VectorReplayBuffer(2000, len(train_envs)), exploration_noise=True)\n",
    "test_collector = ts.data.Collector(policy, test_envs, exploration_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: W&B API key is configured (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Resuming run <strong><a href=\"https://wandb.ai/penalty-shot-project/test-project/runs/sac\" target=\"_blank\">Devanshu Singla</a></strong> to <a href=\"https://wandb.ai/penalty-shot-project/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logging\n",
    "logger = WandbLogger(\n",
    "    save_interval=1,\n",
    "    project=\"test-project\",\n",
    "    name='Devanshu Singla',\n",
    "    entity='penalty-shot-project',\n",
    "    run_id='sac'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 10001it [00:23, 419.15it/s, env_step=10000, len=0, loss/actor=-0.941, loss/critic1=0.008, loss/critic2=0.008, n/ep=0, n/st=10, rew=0.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: 0.580000 ± 0.814616, best_reward: 0.900000 ± 0.435890 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 10001it [00:23, 422.42it/s, env_step=20000, len=0, loss/actor=-1.570, loss/critic1=0.007, loss/critic2=0.007, n/ep=0, n/st=10, rew=0.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: 0.920000 ± 0.391918, best_reward: 0.920000 ± 0.391918 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 10001it [00:24, 411.13it/s, env_step=30000, len=0, loss/actor=-2.162, loss/critic1=0.006, loss/critic2=0.006, n/ep=0, n/st=10, rew=0.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 0.800000 ± 0.600000, best_reward: 0.920000 ± 0.391918 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 10001it [00:24, 412.83it/s, env_step=40000, len=0, loss/actor=-2.723, loss/critic1=0.004, loss/critic2=0.005, n/ep=0, n/st=10, rew=0.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 0.860000 ± 0.510294, best_reward: 0.920000 ± 0.391918 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 10001it [00:24, 400.63it/s, env_step=50000, len=0, loss/actor=-3.242, loss/critic1=0.004, loss/critic2=0.004, n/ep=0, n/st=10, rew=0.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 0.860000 ± 0.510294, best_reward: 0.920000 ± 0.391918 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 10001it [00:24, 411.76it/s, env_step=60000, len=88, loss/actor=-3.759, loss/critic1=0.002, loss/critic2=0.002, n/ep=1, n/st=10, rew=1.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 0.780000 ± 0.625780, best_reward: 0.920000 ± 0.391918 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 10001it [00:24, 409.94it/s, env_step=70000, len=0, loss/actor=-4.156, loss/critic1=0.004, loss/critic2=0.004, n/ep=0, n/st=10, rew=0.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 0.860000 ± 0.510294, best_reward: 0.920000 ± 0.391918 in #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 10001it [00:24, 415.94it/s, env_step=80000, len=0, loss/actor=-4.620, loss/critic1=0.004, loss/critic2=0.004, n/ep=0, n/st=10, rew=0.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 0.940000 ± 0.341174, best_reward: 0.940000 ± 0.341174 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 10001it [00:23, 423.57it/s, env_step=90000, len=0, loss/actor=-4.889, loss/critic1=0.004, loss/critic2=0.004, n/ep=0, n/st=10, rew=0.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 0.860000 ± 0.510294, best_reward: 0.940000 ± 0.341174 in #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 10001it [00:22, 434.96it/s, env_step=100000, len=0, loss/actor=-5.309, loss/critic1=0.003, loss/critic2=0.004, n/ep=0, n/st=10, rew=0.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 0.880000 ± 0.474974, best_reward: 0.940000 ± 0.341174 in #8\n",
      "Finished training! Use {'test_step': 96986, 'test_episode': 1100, 'test_time': '92.48s', 'test_speed': '1048.73 step/s', 'best_reward': 0.94, 'best_result': '0.94 ± 0.34', 'duration': '332.92s', 'train_time/model': '191.18s', 'train_step': 100000, 'train_episode': 1130, 'train_time/collector': '49.26s', 'train_speed': '415.91 step/s'}\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "result = ts.trainer.offpolicy_trainer(\n",
    "    policy, train_collector, test_collector,\n",
    "    max_epoch=10, step_per_epoch=10000, step_per_collect=10,\n",
    "    update_per_step=0.1, episode_per_test=100, batch_size=64, logger=logger)\n",
    "print(f'Finished training! Use {result}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}